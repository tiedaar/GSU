{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to check whether the three ids - essay_id, essay_id_comp, and filename all point to the \n",
    "# same essays. It takes four arguments:\n",
    "#\n",
    "# dataframe_path - path to the main dataframe which contains fulltexts and essay_id\n",
    "# filename_path - path to the folder with the numbered essay files\n",
    "# essay_id_comp_path - path to the folder with the essay_id_comp labeled files\n",
    "# key_path - path the the keyed dataframe\n",
    "#\n",
    "# It makes lists of full texts pulled using all three id systems, then checks those lists to make sure they are identical\n",
    "\n",
    "def essayKeyChecker(dataframe_path, filename_path, essay_id_comp_path, key_path):\n",
    "    essay_id_full_text = pd.read_csv(dataframe_path, low_memory=False)[['essay_id', 'full_text']].drop_duplicates()\n",
    "    keyed_df = pd.read_csv(key_path)\n",
    "    filename_docs=[]\n",
    "    essay_id_docs=[]\n",
    "    essay_id_comp_docs=[]\n",
    "    for i in range(len(keyed_df)):\n",
    "        essay_id_docs.append(essay_id_full_text[essay_id_full_text['essay_id']==keyed_df.iloc[i]['essay_id']]['full_text'].to_list()[0])\n",
    "        with open(str(filename_path+str(keyed_df.iloc[i]['filename'])+'.txt')) as f:\n",
    "            filename_docs.append(f.read())\n",
    "        with open(str(essay_id_comp_path+keyed_df.iloc[i]['essay_id_comp']+'.txt')) as f:\n",
    "            essay_id_comp_docs.append(f.read())\n",
    "    print('checking alignment of {} full text files'.format(len(keyed_df)))\n",
    "    print('problem at the following index:')\n",
    "    for i in range(len(keyed_df)):\n",
    "        if filename_docs[i]!=essay_id_docs[i] or filename_docs[i]!=essay_id_comp_docs[i] or essay_id_docs[i]!=essay_id_comp_docs[i]:\n",
    "            print(i)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking alignment of 25996 full text files\n",
      "problem at the following index:\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Running the function\n",
    "essayKeyChecker('../persuade_corpus.csv', 'PERSUADE_TXT/', 'essay_files/', 'id_keys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to extract the full text from each file in a folder.  Takes a path to a folder as an argument\n",
    "# and returns a dataframe with two columns: id is the file name and data is the full text.\n",
    "def createTable(path):\n",
    "    file_dict = {}\n",
    "    ids = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for file in ids:\n",
    "        with open(path+file) as f:\n",
    "            data = f.read()\n",
    "        file_dict[file] = data\n",
    "    data_items = file_dict.items()\n",
    "    data_list = list(data_items)\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.columns = ['id', 'data']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two dataframes - number_list is indexed by the numerical ID in the folder Scott shared and essay_id_list \n",
    "# is indexed by essay_id_comp\n",
    "number_list = createTable('PERSUADE_TXT/')\n",
    "essay_id_list = createTable('essay_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id_comp</th>\n",
       "      <th>full_text</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8CE67A7B4BDF</td>\n",
       "      <td>Everyone has either given advice or been on th...</td>\n",
       "      <td>25207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D549C77CB16</td>\n",
       "      <td>There are mny factors that influence using tec...</td>\n",
       "      <td>9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5CEA51DD2414</td>\n",
       "      <td>Did you know that the majority of students cur...</td>\n",
       "      <td>7228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E53A89E4CAB5</td>\n",
       "      <td>Dear, Senator\\n\\nI'am a conserend voter that b...</td>\n",
       "      <td>19196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120174AE39B7</td>\n",
       "      <td>Dear principal\\n\\nAs a student i believe that ...</td>\n",
       "      <td>21798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id_comp                                          full_text filename\n",
       "0  8CE67A7B4BDF  Everyone has either given advice or been on th...    25207\n",
       "1  1D549C77CB16  There are mny factors that influence using tec...     9957\n",
       "2  5CEA51DD2414  Did you know that the majority of students cur...     7228\n",
       "3  E53A89E4CAB5  Dear, Senator\\n\\nI'am a conserend voter that b...    19196\n",
       "4  120174AE39B7  Dear principal\\n\\nAs a student i believe that ...    21798"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes, change the column names, and strip the .txt from the end of the ids\n",
    "combined_list = essay_id_list.merge(number_list, on=\"data\")\n",
    "combined_list.columns = ['essay_id_comp', 'full_text', 'filename']\n",
    "combined_list['essay_id_comp'] = combined_list.essay_id_comp.str.replace('.txt', '')\n",
    "combined_list['filename'] = combined_list.filename.str.replace('.txt', '')\n",
    "combined_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25996\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id_comp</th>\n",
       "      <th>full_text</th>\n",
       "      <th>filename</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>holistic_essay_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8CE67A7B4BDF</td>\n",
       "      <td>Everyone has either given advice or been on th...</td>\n",
       "      <td>25207</td>\n",
       "      <td>AAAXMP138200000740562810_OR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D549C77CB16</td>\n",
       "      <td>There are mny factors that influence using tec...</td>\n",
       "      <td>9957</td>\n",
       "      <td>AAATRP14318001044789</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5CEA51DD2414</td>\n",
       "      <td>Did you know that the majority of students cur...</td>\n",
       "      <td>7228</td>\n",
       "      <td>AAAXMP138200001722342850_OR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E53A89E4CAB5</td>\n",
       "      <td>Dear, Senator\\n\\nI'am a conserend voter that b...</td>\n",
       "      <td>19196</td>\n",
       "      <td>5353239</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120174AE39B7</td>\n",
       "      <td>Dear principal\\n\\nAs a student i believe that ...</td>\n",
       "      <td>21798</td>\n",
       "      <td>2021004468</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id_comp                                          full_text filename  \\\n",
       "0  8CE67A7B4BDF  Everyone has either given advice or been on th...    25207   \n",
       "1  1D549C77CB16  There are mny factors that influence using tec...     9957   \n",
       "2  5CEA51DD2414  Did you know that the majority of students cur...     7228   \n",
       "3  E53A89E4CAB5  Dear, Senator\\n\\nI'am a conserend voter that b...    19196   \n",
       "4  120174AE39B7  Dear principal\\n\\nAs a student i believe that ...    21798   \n",
       "\n",
       "                      essay_id  holistic_essay_score  \n",
       "0  AAAXMP138200000740562810_OR                     4  \n",
       "1         AAATRP14318001044789                     5  \n",
       "2  AAAXMP138200001722342850_OR                     4  \n",
       "3                      5353239                     4  \n",
       "4                   2021004468                     4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the essay_id and holistic_essay scores from the master dataframe. Combine them, check the length, and check\n",
    "# for null values\n",
    "\n",
    "master_df = pd.read_csv('../persuade_corpus.csv', low_memory=False)[['essay_id', 'full_text', 'holistic_essay_score']].drop_duplicates().reset_index(drop=True)\n",
    "final_key_list = combined_list.merge(master_df, on='full_text').reset_index(drop=True)\n",
    "print(len(final_key_list))\n",
    "print(final_key_list.isnull().values.any())\n",
    "final_key_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25996\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_id_comp</th>\n",
       "      <th>holistic_essay_score</th>\n",
       "      <th>filename</th>\n",
       "      <th>nwords</th>\n",
       "      <th>Admiration/Awe_GALC</th>\n",
       "      <th>Amusement_GALC</th>\n",
       "      <th>Anger_GALC</th>\n",
       "      <th>Anxiety_GALC</th>\n",
       "      <th>Beingtouched_GALC</th>\n",
       "      <th>...</th>\n",
       "      <th>acad_av_lemma_construction_freq_log_stdev</th>\n",
       "      <th>news_av_lemma_freq_log_stdev</th>\n",
       "      <th>news_av_construction_freq_log_stdev</th>\n",
       "      <th>news_av_lemma_construction_freq_log_stdev</th>\n",
       "      <th>mag_av_lemma_freq_log_stdev</th>\n",
       "      <th>mag_av_construction_freq_log_stdev</th>\n",
       "      <th>mag_av_lemma_construction_freq_log_stdev</th>\n",
       "      <th>fic_av_lemma_freq_log_stdev</th>\n",
       "      <th>fic_av_construction_freq_log_stdev</th>\n",
       "      <th>fic_av_lemma_construction_freq_log_stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAXMP138200000740562810_OR</td>\n",
       "      <td>8CE67A7B4BDF</td>\n",
       "      <td>4</td>\n",
       "      <td>25207</td>\n",
       "      <td>401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53350.727204</td>\n",
       "      <td>489237.154680</td>\n",
       "      <td>188269.713837</td>\n",
       "      <td>69194.444590</td>\n",
       "      <td>523141.169702</td>\n",
       "      <td>215618.093412</td>\n",
       "      <td>74087.177064</td>\n",
       "      <td>585607.785392</td>\n",
       "      <td>189674.745932</td>\n",
       "      <td>82362.888418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAATRP14318001044789</td>\n",
       "      <td>1D549C77CB16</td>\n",
       "      <td>5</td>\n",
       "      <td>9957</td>\n",
       "      <td>519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>...</td>\n",
       "      <td>84982.005646</td>\n",
       "      <td>601951.944262</td>\n",
       "      <td>234230.789288</td>\n",
       "      <td>103589.568520</td>\n",
       "      <td>645840.947315</td>\n",
       "      <td>262549.754574</td>\n",
       "      <td>110424.796041</td>\n",
       "      <td>723309.224262</td>\n",
       "      <td>242698.473784</td>\n",
       "      <td>132408.480219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAXMP138200001722342850_OR</td>\n",
       "      <td>5CEA51DD2414</td>\n",
       "      <td>4</td>\n",
       "      <td>7228</td>\n",
       "      <td>372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>46829.731988</td>\n",
       "      <td>439442.732543</td>\n",
       "      <td>184474.738265</td>\n",
       "      <td>73899.413069</td>\n",
       "      <td>471573.417663</td>\n",
       "      <td>198353.207256</td>\n",
       "      <td>74302.332894</td>\n",
       "      <td>528110.237696</td>\n",
       "      <td>213493.762108</td>\n",
       "      <td>84516.752756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5353239</td>\n",
       "      <td>E53A89E4CAB5</td>\n",
       "      <td>4</td>\n",
       "      <td>19196</td>\n",
       "      <td>473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>...</td>\n",
       "      <td>112610.880402</td>\n",
       "      <td>705367.885638</td>\n",
       "      <td>213947.177799</td>\n",
       "      <td>149410.753621</td>\n",
       "      <td>758839.224575</td>\n",
       "      <td>233121.873893</td>\n",
       "      <td>158628.987693</td>\n",
       "      <td>841665.358075</td>\n",
       "      <td>239855.646653</td>\n",
       "      <td>178841.113231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021004468</td>\n",
       "      <td>120174AE39B7</td>\n",
       "      <td>4</td>\n",
       "      <td>21798</td>\n",
       "      <td>211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91779.428266</td>\n",
       "      <td>714543.266075</td>\n",
       "      <td>134882.302618</td>\n",
       "      <td>112743.434223</td>\n",
       "      <td>765949.242037</td>\n",
       "      <td>137868.174323</td>\n",
       "      <td>117844.608539</td>\n",
       "      <td>860698.191333</td>\n",
       "      <td>171388.047766</td>\n",
       "      <td>140480.780184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      essay_id essay_id_comp  holistic_essay_score filename  \\\n",
       "0  AAAXMP138200000740562810_OR  8CE67A7B4BDF                     4    25207   \n",
       "1         AAATRP14318001044789  1D549C77CB16                     5     9957   \n",
       "2  AAAXMP138200001722342850_OR  5CEA51DD2414                     4     7228   \n",
       "3                      5353239  E53A89E4CAB5                     4    19196   \n",
       "4                   2021004468  120174AE39B7                     4    21798   \n",
       "\n",
       "   nwords  Admiration/Awe_GALC  Amusement_GALC  Anger_GALC  Anxiety_GALC  \\\n",
       "0     401                  0.0        0.000000    0.000000           0.0   \n",
       "1     519                  0.0        0.001927    0.003854           0.0   \n",
       "2     372                  0.0        0.000000    0.000000           0.0   \n",
       "3     473                  0.0        0.002114    0.000000           0.0   \n",
       "4     211                  0.0        0.000000    0.000000           0.0   \n",
       "\n",
       "   Beingtouched_GALC  ...  acad_av_lemma_construction_freq_log_stdev  \\\n",
       "0           0.000000  ...                               53350.727204   \n",
       "1           0.001927  ...                               84982.005646   \n",
       "2           0.000000  ...                               46829.731988   \n",
       "3           0.002114  ...                              112610.880402   \n",
       "4           0.000000  ...                               91779.428266   \n",
       "\n",
       "   news_av_lemma_freq_log_stdev  news_av_construction_freq_log_stdev  \\\n",
       "0                 489237.154680                        188269.713837   \n",
       "1                 601951.944262                        234230.789288   \n",
       "2                 439442.732543                        184474.738265   \n",
       "3                 705367.885638                        213947.177799   \n",
       "4                 714543.266075                        134882.302618   \n",
       "\n",
       "   news_av_lemma_construction_freq_log_stdev  mag_av_lemma_freq_log_stdev  \\\n",
       "0                               69194.444590                523141.169702   \n",
       "1                              103589.568520                645840.947315   \n",
       "2                               73899.413069                471573.417663   \n",
       "3                              149410.753621                758839.224575   \n",
       "4                              112743.434223                765949.242037   \n",
       "\n",
       "   mag_av_construction_freq_log_stdev  \\\n",
       "0                       215618.093412   \n",
       "1                       262549.754574   \n",
       "2                       198353.207256   \n",
       "3                       233121.873893   \n",
       "4                       137868.174323   \n",
       "\n",
       "   mag_av_lemma_construction_freq_log_stdev  fic_av_lemma_freq_log_stdev  \\\n",
       "0                              74087.177064                585607.785392   \n",
       "1                             110424.796041                723309.224262   \n",
       "2                              74302.332894                528110.237696   \n",
       "3                             158628.987693                841665.358075   \n",
       "4                             117844.608539                860698.191333   \n",
       "\n",
       "   fic_av_construction_freq_log_stdev  \\\n",
       "0                       189674.745932   \n",
       "1                       242698.473784   \n",
       "2                       213493.762108   \n",
       "3                       239855.646653   \n",
       "4                       171388.047766   \n",
       "\n",
       "   fic_av_lemma_construction_freq_log_stdev  \n",
       "0                              82362.888418  \n",
       "1                             132408.480219  \n",
       "2                              84516.752756  \n",
       "3                             178841.113231  \n",
       "4                             140480.780184  \n",
       "\n",
       "[5 rows x 1336 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring up the NLP indices (not including GAMAT), combine them with with the keyed df. Check for length, null values\n",
    "NLPindices = pd.read_csv('PERSUADE_Combined_Results.csv',index_col = 0).reset_index(drop=True)\n",
    "NLPindices.filename = NLPindices.filename.astype('str')\n",
    "keyed_df = final_key_list[['essay_id', 'essay_id_comp', 'holistic_essay_score', 'filename']].merge(NLPindices, on='filename')\n",
    "print(len(keyed_df))\n",
    "print(keyed_df.isnull().values.any())\n",
    "keyed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id_comp</th>\n",
       "      <th>error_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>error_count_per_100_words</th>\n",
       "      <th>duplication</th>\n",
       "      <th>duplication_per_100_words</th>\n",
       "      <th>grammar</th>\n",
       "      <th>grammar_per_100_words</th>\n",
       "      <th>misspelling</th>\n",
       "      <th>misspelling_per_100_words</th>\n",
       "      <th>...</th>\n",
       "      <th>WORST_THAN</th>\n",
       "      <th>WORTH_WHILE</th>\n",
       "      <th>WRONG_APOSTROPHE</th>\n",
       "      <th>YOULL_WILL</th>\n",
       "      <th>YOUR</th>\n",
       "      <th>YOURS_APOSTROPHE</th>\n",
       "      <th>YOUR_NN</th>\n",
       "      <th>YOUR_S</th>\n",
       "      <th>YOUR_SHOULD</th>\n",
       "      <th>YOU_THING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>25</td>\n",
       "      <td>251</td>\n",
       "      <td>9.960159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>9.960159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>110</td>\n",
       "      <td>646</td>\n",
       "      <td>17.027864</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110</td>\n",
       "      <td>17.027864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006ED03C701</td>\n",
       "      <td>70</td>\n",
       "      <td>265</td>\n",
       "      <td>26.415094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>15.094340</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000A58BC095E</td>\n",
       "      <td>15</td>\n",
       "      <td>254</td>\n",
       "      <td>5.905512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.937008</td>\n",
       "      <td>5</td>\n",
       "      <td>1.968504</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>120</td>\n",
       "      <td>386</td>\n",
       "      <td>31.088083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>18.134715</td>\n",
       "      <td>20</td>\n",
       "      <td>5.181347</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id_comp  error_count  word_count  error_count_per_100_words  \\\n",
       "0  0000D23A521A           25         251                   9.960159   \n",
       "1  00066EA9880D          110         646                  17.027864   \n",
       "2  0006ED03C701           70         265                  26.415094   \n",
       "3  000A58BC095E           15         254                   5.905512   \n",
       "4  000BAD50D026          120         386                  31.088083   \n",
       "\n",
       "   duplication  duplication_per_100_words  grammar  grammar_per_100_words  \\\n",
       "0            0                        0.0        0               0.000000   \n",
       "1            0                        0.0        0               0.000000   \n",
       "2            0                        0.0        0               0.000000   \n",
       "3            0                        0.0       10               3.937008   \n",
       "4            0                        0.0       70              18.134715   \n",
       "\n",
       "   misspelling  misspelling_per_100_words  ...  WORST_THAN  WORTH_WHILE  \\\n",
       "0           25                   9.960159  ...           0            0   \n",
       "1          110                  17.027864  ...           0            0   \n",
       "2           40                  15.094340  ...           0            0   \n",
       "3            5                   1.968504  ...           0            0   \n",
       "4           20                   5.181347  ...           0            0   \n",
       "\n",
       "   WRONG_APOSTROPHE  YOULL_WILL  YOUR  YOURS_APOSTROPHE  YOUR_NN  YOUR_S  \\\n",
       "0                 0           0     0                 0        0       0   \n",
       "1                 0           0     0                 0        0       0   \n",
       "2                 0           0     0                 0        0       0   \n",
       "3                 0           0     0                 0        0       0   \n",
       "4                 0           0     0                 0        0       0   \n",
       "\n",
       "   YOUR_SHOULD  YOU_THING  \n",
       "0            0          0  \n",
       "1            0          0  \n",
       "2            0          0  \n",
       "3            0          0  \n",
       "4            0          0  \n",
       "\n",
       "[5 rows x 472 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and clean up the GAMAT results. These are keyed to essay_id_comp, but that shouldn't be a problem.\n",
    "GAMATresults = pd.read_csv('GAMATresults.csv')\n",
    "GAMATresults['filename'] = GAMATresults['filename'].str.replace('C:/Users/wmorris5/Desktop/essay_files', '')\n",
    "GAMATresults['filename'] = GAMATresults['filename'].str[1:]\n",
    "GAMATresults['filename'] = GAMATresults['filename'].str.replace('.txt', '')\n",
    "GAMATresults = GAMATresults.rename(columns={'filename':'essay_id_comp'})\n",
    "GAMATresults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25996\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_id_comp</th>\n",
       "      <th>holistic_essay_score</th>\n",
       "      <th>filename</th>\n",
       "      <th>nwords</th>\n",
       "      <th>Admiration/Awe_GALC</th>\n",
       "      <th>Amusement_GALC</th>\n",
       "      <th>Anger_GALC</th>\n",
       "      <th>Anxiety_GALC</th>\n",
       "      <th>Beingtouched_GALC</th>\n",
       "      <th>...</th>\n",
       "      <th>WORST_THAN</th>\n",
       "      <th>WORTH_WHILE</th>\n",
       "      <th>WRONG_APOSTROPHE</th>\n",
       "      <th>YOULL_WILL</th>\n",
       "      <th>YOUR</th>\n",
       "      <th>YOURS_APOSTROPHE</th>\n",
       "      <th>YOUR_NN</th>\n",
       "      <th>YOUR_S</th>\n",
       "      <th>YOUR_SHOULD</th>\n",
       "      <th>YOU_THING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAXMP138200000740562810_OR</td>\n",
       "      <td>8CE67A7B4BDF</td>\n",
       "      <td>4</td>\n",
       "      <td>25207</td>\n",
       "      <td>401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAATRP14318001044789</td>\n",
       "      <td>1D549C77CB16</td>\n",
       "      <td>5</td>\n",
       "      <td>9957</td>\n",
       "      <td>519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAXMP138200001722342850_OR</td>\n",
       "      <td>5CEA51DD2414</td>\n",
       "      <td>4</td>\n",
       "      <td>7228</td>\n",
       "      <td>372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5353239</td>\n",
       "      <td>E53A89E4CAB5</td>\n",
       "      <td>4</td>\n",
       "      <td>19196</td>\n",
       "      <td>473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021004468</td>\n",
       "      <td>120174AE39B7</td>\n",
       "      <td>4</td>\n",
       "      <td>21798</td>\n",
       "      <td>211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      essay_id essay_id_comp  holistic_essay_score filename  \\\n",
       "0  AAAXMP138200000740562810_OR  8CE67A7B4BDF                     4    25207   \n",
       "1         AAATRP14318001044789  1D549C77CB16                     5     9957   \n",
       "2  AAAXMP138200001722342850_OR  5CEA51DD2414                     4     7228   \n",
       "3                      5353239  E53A89E4CAB5                     4    19196   \n",
       "4                   2021004468  120174AE39B7                     4    21798   \n",
       "\n",
       "   nwords  Admiration/Awe_GALC  Amusement_GALC  Anger_GALC  Anxiety_GALC  \\\n",
       "0     401                  0.0        0.000000    0.000000           0.0   \n",
       "1     519                  0.0        0.001927    0.003854           0.0   \n",
       "2     372                  0.0        0.000000    0.000000           0.0   \n",
       "3     473                  0.0        0.002114    0.000000           0.0   \n",
       "4     211                  0.0        0.000000    0.000000           0.0   \n",
       "\n",
       "   Beingtouched_GALC  ...  WORST_THAN  WORTH_WHILE  WRONG_APOSTROPHE  \\\n",
       "0           0.000000  ...           0            0                 0   \n",
       "1           0.001927  ...           0            0                 0   \n",
       "2           0.000000  ...           0            0                 0   \n",
       "3           0.002114  ...           0            0                 0   \n",
       "4           0.000000  ...           0            0                 0   \n",
       "\n",
       "   YOULL_WILL  YOUR  YOURS_APOSTROPHE  YOUR_NN  YOUR_S  YOUR_SHOULD  YOU_THING  \n",
       "0           0     0                 0        0       0            0          0  \n",
       "1           0     0                 0        0       0            0          0  \n",
       "2           0     0                 0        0       0            0          0  \n",
       "3           0     0                 0        0       0            0          0  \n",
       "4           0     0                 0        0       0            0          0  \n",
       "\n",
       "[5 rows x 1807 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the GAMAT results onto our keyed_df dataframe. Check everything\n",
    "keyed_df = keyed_df.merge(GAMATresults, on='essay_id_comp')\n",
    "print(len(keyed_df))\n",
    "print(keyed_df.isnull().values.any())\n",
    "keyed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the full dataframe to a csv\n",
    "keyed_df.to_csv('PERSUADE_NLP_indices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem at the following index:\n",
      "done!\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
